"""
RAG Chain for Daily Report Chatbot

ì¼ì¼ë³´ê³ ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ RAG ì±—ë´‡ ì²´ì¸
LangChain ìŠ¤íƒ€ì¼ë¡œ êµ¬ì„±
"""
from typing import List, Optional, Dict, Any
from datetime import date, datetime, timedelta
import re

from app.infrastructure.vector_store_advanced import get_vector_store
from app.domain.report.search.retriever import UnifiedRetriever, UnifiedSearchResult
from app.llm.client import LLMClient


class ReportRAGChain:
    """ì¼ì¼ë³´ê³ ì„œ RAG ì²´ì¸"""
    
    def __init__(
        self,
        owner: str,
        retriever: Optional[UnifiedRetriever] = None,
        llm: Optional[LLMClient] = None,
        top_k: int = 5
    ):
        """
        ì´ˆê¸°í™”
        
        Args:
            owner: ìž‘ì„±ìž ì´ë¦„
            retriever: UnifiedRetriever ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ìžë™ ìƒì„±)
            llm: LLMClient ì¸ìŠ¤í„´ìŠ¤ (Noneì´ë©´ ìžë™ ìƒì„±)
            top_k: ê²€ìƒ‰ ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸ê°’: 5)
        """
        self.owner = owner
        self.top_k = top_k
        
        # Retriever ì´ˆê¸°í™”
        if retriever is None:
            # daily_reports_advanced ì»¬ë ‰ì…˜ ì‚¬ìš©
            import os
            vector_store = get_vector_store()
            collection = vector_store.get_collection()
            embedding_model_type = os.getenv("REPORT_EMBEDDING_MODEL_TYPE", "hf")
            self.retriever = UnifiedRetriever(
                collection=collection,
                embedding_model_type=embedding_model_type
            )
        else:
            self.retriever = retriever
        
        # LLM ì´ˆê¸°í™”
        if llm is None:
            self.llm = LLMClient(
                model="gpt-4o-mini",
                temperature=0.7,
                max_tokens=2000
            )
        else:
            self.llm = llm
    
    def _is_unresolved_task_query(self, query: str) -> bool:
        """
        ë¯¸ì¢…ê²° ì—…ë¬´ ê´€ë ¨ ì§ˆì˜ì¸ì§€ íŒë‹¨
        
        Args:
            query: ì‚¬ìš©ìž ì§ˆë¬¸
            
        Returns:
            ë¯¸ì¢…ê²° ì—…ë¬´ ì§ˆì˜ ì—¬ë¶€
        """
        query_lower = query.lower()
        unresolved_keywords = ["ë¯¸ì¢…ê²°", "ë¯¸ì™„ë£Œ", "ì²˜ë¦¬ ëª»í•œ", "ì•ˆ í•œ", "ì•ˆí•œ", "ì•ˆ ëë‚œ", "ì•ˆëë‚œ"]
        return any(keyword in query_lower for keyword in unresolved_keywords)
    
    def _parse_date_from_metadata(self, metadata: Dict[str, Any]) -> Optional[date]:
        """
        ë©”íƒ€ë°ì´í„°ì—ì„œ ë‚ ì§œ íŒŒì‹± (ìƒˆë¡œìš´ 4ì²­í¬ êµ¬ì¡°: date í•„ë“œë§Œ ì‚¬ìš©)
        
        Args:
            metadata: ì²­í¬ ë©”íƒ€ë°ì´í„°
            
        Returns:
            íŒŒì‹±ëœ date ê°ì²´ ë˜ëŠ” None
        """
        date_str = metadata.get("date")
        if not date_str:
            return None
        
        try:
            # YYYY-MM-DD í˜•ì‹ íŒŒì‹±
            return datetime.strptime(date_str, "%Y-%m-%d").date()
        except (ValueError, TypeError):
            return None
    
    def _filter_completed_unresolved_tasks(
        self,
        issue_results: List[UnifiedSearchResult]
    ) -> List[UnifiedSearchResult]:
        """
        ë¯¸ì¢…ê²° ì—…ë¬´ ì¤‘ ë‹¤ìŒ ë‚  ì‹¤ì œë¡œ ìˆ˜í–‰ëœ í•­ëª© ì œì™¸
        
        Args:
            issue_results: ë¯¸ì¢…ê²° ì—…ë¬´ ê²€ìƒ‰ ê²°ê³¼
            
        Returns:
            í•„í„°ë§ëœ ê²°ê³¼ (ì§„í–‰ë˜ì§€ ì•Šì€ ë¯¸ì¢…ê²° ì—…ë¬´ë§Œ)
        """
        if not issue_results:
            return []
        
        filtered_results = []
        
        for issue_result in issue_results:
            issue_date = self._parse_date_from_metadata(issue_result.metadata)
            if not issue_date:
                # ë‚ ì§œ ì •ë³´ ì—†ìœ¼ë©´ í¬í•¨
                filtered_results.append(issue_result)
                continue
            
            # ë‹¤ìŒ ë‚  ë‚ ì§œ ê³„ì‚°
            next_day = issue_date + timedelta(days=1)
            
            # ë‹¤ìŒ ë‚ ì˜ task ê²€ìƒ‰ (ê°™ì€ ì—…ë¬´ê°€ ìˆ˜í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸)
            next_day_tasks = self.retriever.search_daily(
                query=issue_result.text,  # ë¯¸ì¢…ê²° ì—…ë¬´ í…ìŠ¤íŠ¸ë¡œ ê²€ìƒ‰
                owner=self.owner,
                single_date=next_day.strftime("%Y-%m-%d"),
                n_results=10,
                chunk_types=["detail"]  # detail íƒ€ìž…ë§Œ (ìƒˆë¡œìš´ 4ì²­í¬ êµ¬ì¡°)
            )
            
            # ìœ ì‚¬ë„ê°€ ë†’ì€ taskê°€ ìžˆìœ¼ë©´ ìˆ˜í–‰ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼
            is_completed = False
            for task in next_day_tasks:
                # í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê°„ë‹¨ ì²´í¬ (ë” ì •êµí•œ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥)
                issue_text_lower = issue_result.text.lower()
                task_text_lower = task.text.lower()
                
                # í‚¤ì›Œë“œ ë§¤ì¹­ (50% ì´ìƒ ê²¹ì¹˜ë©´ ìˆ˜í–‰ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼)
                issue_words = set(issue_text_lower.split())
                task_words = set(task_text_lower.split())
                if issue_words and task_words:
                    overlap = len(issue_words & task_words) / len(issue_words)
                    if overlap > 0.5:  # 50% ì´ìƒ ê²¹ì¹˜ë©´
                        is_completed = True
                        break
            
            # ìˆ˜í–‰ë˜ì§€ ì•Šì€ ë¯¸ì¢…ê²° ì—…ë¬´ë§Œ í¬í•¨
            if not is_completed:
                filtered_results.append(issue_result)
        
        return filtered_results
    
    def retrieve(
        self,
        query: str,
        date_range: Optional[Dict[str, date]] = None,
        reference_date: Optional[date] = None
    ) -> List[UnifiedSearchResult]:
        """
        ChromaDBì—ì„œ ê´€ë ¨ ì¼ì¼ë³´ê³ ì„œ ê²€ìƒ‰
        
        Args:
            query: ì‚¬ìš©ìž ì§ˆë¬¸
            date_range: ë‚ ì§œ ë²”ìœ„ í•„í„° (ì˜ˆ: {"start": date(2025, 1, 1), "end": date(2025, 12, 31)})
            reference_date: ê¸°ì¤€ ë‚ ì§œ (ìƒëŒ€ì  ë‚ ì§œ ê³„ì‚°ìš©)
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ë‚ ì§œ ì •ë ¬ë¨)
        """
        # ê¸°ì¤€ ë‚ ì§œ ì„¤ì • (ìƒëŒ€ì  ë‚ ì§œ ê³„ì‚°ìš©)
        base_date = reference_date if reference_date else date.today()
        
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì • (ê¸°ë³¸ê°’: ìµœê·¼ 1ë…„)
        if date_range is None:
            end_date = base_date
            start_date = end_date - timedelta(days=365)
            period_start = start_date.strftime("%Y-%m-%d")
            period_end = end_date.strftime("%Y-%m-%d")
        else:
            period_start = date_range.get("start", base_date - timedelta(days=365)).strftime("%Y-%m-%d")
            period_end = date_range.get("end", base_date).strftime("%Y-%m-%d")
        
        # ë¯¸ì¢…ê²° ì—…ë¬´ ì§ˆì˜ì¸ì§€ í™•ì¸
        is_unresolved_query = self._is_unresolved_task_query(query)
        
        if is_unresolved_query:
            # ë¯¸ì¢…ê²° ì—…ë¬´ ì§ˆì˜: pending íƒ€ìž…ë§Œ ê²€ìƒ‰
            results = self.retriever.search_daily(
                query=query,
                owner=self.owner,
                period_start=period_start,
                period_end=period_end,
                n_results=self.top_k * 2,  # í•„í„°ë§ ì „ ë” ë§Žì´ ê°€ì ¸ì˜¤ê¸°
                chunk_types=["pending"]  # pending íƒ€ìž…ë§Œ (ìƒˆë¡œìš´ 4ì²­í¬ êµ¬ì¡°)
            )
            
            # ë‹¤ìŒ ë‚  ìˆ˜í–‰ëœ ì—…ë¬´ ì œì™¸
            results = self._filter_completed_unresolved_tasks(results)
            
            # top_kë¡œ ì œí•œ
            results = results[:self.top_k]
        else:
            # ì¼ë°˜ ì§ˆì˜: detail, pending, plan_note ëª¨ë‘ ê²€ìƒ‰
            results = self.retriever.search_daily(
                query=query,
                owner=self.owner,
                period_start=period_start,
                period_end=period_end,
                n_results=self.top_k,
                chunk_types=["detail", "pending", "plan_note"]  # ìƒˆë¡œìš´ 4ì²­í¬ êµ¬ì¡°
            )
        
        # ë‚ ì§œ ê¸°ì¤€ ì •ë ¬ (ìµœì‹ ìˆœ, ì—°ë„ í¬í•¨ ì •í™•í•œ ì •ë ¬)
        results.sort(
            key=lambda r: (
                self._parse_date_from_metadata(r.metadata) or date.min,
                -r.score  # ê°™ì€ ë‚ ì§œë©´ ìœ ì‚¬ë„ ë†’ì€ ìˆœ
            ),
            reverse=True  # ìµœì‹ ìˆœ
        )
        
        return results
    
    def format_context(self, results: List[UnifiedSearchResult]) -> str:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ LLM ì»¨í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ… (ë‚ ì§œ ì •ë ¬ëœ ìˆœì„œë¡œ)
        
        Args:
            results: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ì´ë¯¸ ë‚ ì§œ ì •ë ¬ë¨)
            
        Returns:
            í¬ë§·íŒ…ëœ ì»¨í…ìŠ¤íŠ¸ ë¬¸ìžì—´
        """
        if not results:
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        
        for idx, result in enumerate(results, 1):
            # ë©”íƒ€ë°ì´í„°ì—ì„œ ë‚ ì§œ, ì‹œê°„, ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
            metadata = result.metadata
            date_str = metadata.get("date", "ë‚ ì§œ ì •ë³´ ì—†ìŒ")
            
            # ë‚ ì§œ íŒŒì‹±í•˜ì—¬ ì •í™•í•œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
            parsed_date = self._parse_date_from_metadata(metadata)
            if parsed_date:
                date_str = parsed_date.strftime("%Y-%m-%d")  # ì—°ë„ í¬í•¨ ì •í™•í•œ í˜•ì‹
            
            time_slot = metadata.get("time_slot", "")
            chunk_type = result.chunk_type
            category = metadata.get("category", "")
            
            # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
            context_line = f"[{idx}] "
            
            # ë‚ ì§œ ì •ë³´ (ì—°ë„ í¬í•¨)
            context_line += f"ë‚ ì§œ: {date_str}"
            
            # ì‹œê°„ ì •ë³´ (ìžˆìœ¼ë©´)
            if time_slot:
                context_line += f", ì‹œê°„: {time_slot}"
            
            # ì²­í¬ íƒ€ìž… (ìƒˆë¡œìš´ 4ì²­í¬ êµ¬ì¡°ë§Œ ì‚¬ìš©)
            type_map = {
                "summary": "ìš”ì•½",
                "detail": "ì„¸ë¶€ ì—…ë¬´",
                "pending": "ë¯¸ì¢…ê²°",
                "plan_note": "ê³„íš/íŠ¹ì´ì‚¬í•­"
            }
            context_line += f", ìœ í˜•: {type_map.get(chunk_type, chunk_type)}"
            
            # ì¹´í…Œê³ ë¦¬ (ìžˆìœ¼ë©´)
            if category:
                context_line += f", ì¹´í…Œê³ ë¦¬: {category}"
            
            context_line += "\n"
            context_line += f"ë‚´ìš©: {result.text}\n"
            
            context_parts.append(context_line)
        
        return "\n---\n".join(context_parts)
    
    async def generate_response(
        self,
        query: str,
        date_range: Optional[Dict[str, date]] = None,
        reference_date: Optional[date] = None
    ) -> Dict[str, Any]:
        """
        RAG íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ê²€ìƒ‰ â†’ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± â†’ LLM ì‘ë‹µ ìƒì„±
        
        Args:
            query: ì‚¬ìš©ìž ì§ˆë¬¸
            date_range: ë‚ ì§œ ë²”ìœ„ í•„í„°
            
        Returns:
            {
                "answer": str,  # LLM ì‘ë‹µ
                "sources": List[Dict],  # ê·¼ê±° ë¬¸ì„œ ì •ë³´
                "has_results": bool  # ê²€ìƒ‰ ê²°ê³¼ ì¡´ìž¬ ì—¬ë¶€
            }
        """
        # ê¸°ì¤€ ë‚ ì§œ ì„¤ì • (ìƒëŒ€ì  ë‚ ì§œ ê³„ì‚°ìš©)
        base_date = reference_date if reference_date else date.today()
        
        # 1. ê²€ìƒ‰
        results = self.retrieve(query, date_range, reference_date)
        
        # 2. ê²€ìƒ‰ ê²°ê³¼ ì—†ìœ¼ë©´ ë°”ë¡œ ë°˜í™˜
        if not results:
            # ë¯¸ì¢…ê²° ì—…ë¬´ ì§ˆì˜ì¸ ê²½ìš° íŠ¹ë³„ ë©”ì‹œì§€
            if self._is_unresolved_task_query(query):
                return {
                    "answer": "ìµœê·¼ ë¯¸ì¢…ê²° ì—…ë¬´ëŠ” ì—†ìŠµë‹ˆë‹¤.",
                    "sources": [],
                    "has_results": False
                }
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì¼ì¼ë³´ê³ ì„œ ë°ì´í„°ì—ì„œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œê±°ë‚˜, ê²€ìƒ‰ ê¸°ê°„ì„ ì¡°ì •í•´ì£¼ì„¸ìš”.",
                "sources": [],
                "has_results": False
            }
        
        # 3. ì»¨í…ìŠ¤íŠ¸ í¬ë§·íŒ…
        context = self.format_context(results)
        
        # 4. LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        is_unresolved_query = self._is_unresolved_task_query(query)
        
        # ê¸°ì¤€ ë‚ ì§œ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        base_date_str = base_date.strftime("%Yë…„ %mì›” %dì¼")
        
        # ê¸°ì¤€ ë‚ ì§œê°€ ì†í•œ ì£¼ì˜ ì›”ìš”ì¼~ê¸ˆìš”ì¼ ê³„ì‚°
        from datetime import timedelta
        weekday = base_date.weekday()  # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
        monday = base_date - timedelta(days=weekday)
        friday = monday + timedelta(days=4)
        this_week_range = f"{monday.strftime('%Y-%m-%d')} ~ {friday.strftime('%Y-%m-%d')}"
        this_week_range_kr = f"{monday.strftime('%Yë…„ %mì›” %dì¼')} ~ {friday.strftime('%Yë…„ %mì›” %dì¼')}"
        
        system_prompt = f"""ë‹¹ì‹ ì€ ì¼ì¼ë³´ê³ ì„œ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì „ë¬¸ ì–´ì‹œìŠ¤í„´íŠ¸ìž…ë‹ˆë‹¤.

âš ï¸ ì¤‘ìš”: í˜„ìž¬ ê¸°ì¤€ ë‚ ì§œëŠ” {base_date_str} ({base_date.strftime("%Y-%m-%d")})ìž…ë‹ˆë‹¤.
ì´ ê¸°ì¤€ ë‚ ì§œëŠ” ì‚¬ìš©ìžê°€ ì¼ì¼ë³´ê³ ì„œ ë‚ ì§œ ì„¤ì •ì—ì„œ ì„¤ì •í•œ ë‚ ì§œìž…ë‹ˆë‹¤.

ðŸ“… ë‚ ì§œ ë²”ìœ„ ì •ì˜:
- "ì´ë²ˆ ì£¼": ê¸°ì¤€ ë‚ ì§œ({base_date_str})ê°€ ì†í•œ ì£¼ì˜ ì›”ìš”ì¼~ê¸ˆìš”ì¼ = {this_week_range_kr} ({this_week_range})
- "ì§€ë‚œ ì£¼": ì´ë²ˆ ì£¼ ë°”ë¡œ ì „ ì£¼ì˜ ì›”ìš”ì¼~ê¸ˆìš”ì¼
- "ì´ë²ˆ ë‹¬": ê¸°ì¤€ ë‚ ì§œê°€ ì†í•œ ë‹¬ì˜ 1ì¼~ë§ì¼
- "ì§€ë‚œ ë‹¬": ì´ë²ˆ ë‹¬ ë°”ë¡œ ì „ ë‹¬ì˜ 1ì¼~ë§ì¼

ê·œì¹™:
1. ì œê³µëœ ê²€ìƒ‰ ê²°ê³¼(ì¼ì¼ë³´ê³ ì„œ ë°ì´í„°)ë§Œì„ ê·¼ê±°ë¡œ ë‹µë³€í•˜ì„¸ìš”.
2. ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ì¶”ì¸¡í•˜ê±°ë‚˜ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
3. ë‚ ì§œ, ì‹œê°„, ì—…ë¬´ ë‚´ìš© ë“±ì€ ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì •í™•ížˆ ì¸ìš©í•˜ì„¸ìš”.
4. ì—¬ëŸ¬ ê²°ê³¼ê°€ ìžˆìœ¼ë©´ ë‚ ì§œìˆœ(ìµœì‹ ìˆœ)ìœ¼ë¡œ ì •ë¦¬í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.
5. ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ "ë°ì´í„°ì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ëª…í™•ížˆ ë‹µë³€í•˜ì„¸ìš”.
6. ìžì—°ìŠ¤ëŸ½ê³  ì¹œì ˆí•œ í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”.
7. í•„ìš”ì‹œ ë‚ ì§œ, ì‹œê°„, ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ í¬í•¨í•´ì„œ ë‹µë³€í•˜ì„¸ìš”.
8. ë‚ ì§œ ë¹„êµ ì‹œ ì—°ë„(YYYY), ì›”(MM), ì¼(DD)ì„ ëª¨ë‘ ê³ ë ¤í•˜ì—¬ ì •í™•ížˆ ë¹„êµí•˜ì„¸ìš”.
9. ì˜ˆ: 2025-01-15ëŠ” 2024-12-20ë³´ë‹¤ ìµœì‹ ìž…ë‹ˆë‹¤.
10. "ì´ë²ˆ ì£¼"ë¼ê³  ì§ˆë¬¸í•˜ë©´ ë°˜ë“œì‹œ {this_week_range} ë²”ìœ„ì˜ ë°ì´í„°ë§Œ ê²€ìƒ‰í•˜ì„¸ìš”.

ë‹µë³€ í˜•ì‹:
- ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€
- ê·¼ê±°ê°€ ë˜ëŠ” ë‚ ì§œ/ì‹œê°„ ì •ë³´ í¬í•¨ (ì—°ë„ í¬í•¨)
- ì—¬ëŸ¬ ê²°ê³¼ê°€ ìžˆìœ¼ë©´ ë‚ ì§œìˆœ(ìµœì‹ ìˆœ) ëª©ë¡ìœ¼ë¡œ ì •ë¦¬
- ìƒëŒ€ì  ë‚ ì§œ í‘œí˜„ì„ ì‚¬ìš©í•  ë•ŒëŠ” êµ¬ì²´ì ì¸ ë‚ ì§œ ë²”ìœ„ë¥¼ ëª…ì‹œí•˜ì„¸ìš” (ì˜ˆ: "ì´ë²ˆ ì£¼({this_week_range})")"""
        
        if is_unresolved_query:
            system_prompt += "\n\níŠ¹ë³„ ê·œì¹™ (ë¯¸ì¢…ê²° ì—…ë¬´ ì§ˆì˜):\n- ì œê³µëœ ê²€ìƒ‰ ê²°ê³¼ëŠ” ì´ë¯¸ ë‹¤ìŒ ë‚  ìˆ˜í–‰ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì—¬ í•„í„°ë§ëœ 'ì§„í–‰ë˜ì§€ ì•Šì€' ë¯¸ì¢…ê²° ì—…ë¬´ë§Œ í¬í•¨í•©ë‹ˆë‹¤.\n- ë”°ë¼ì„œ ê²€ìƒ‰ ê²°ê³¼ì— ë‚˜ì˜¨ í•­ëª©ë“¤ì€ ëª¨ë‘ ì•„ì§ ë¯¸ì¢…ê²° ìƒíƒœìž…ë‹ˆë‹¤."
        
        user_prompt = f"""ì‚¬ìš©ìž ì§ˆë¬¸: {query}

ê²€ìƒ‰ëœ ì¼ì¼ë³´ê³ ì„œ ë°ì´í„°:
{context}

ìœ„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ìš©ìž ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”. ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ì •ë³´ëŠ” ì ˆëŒ€ ë§Œë“¤ì–´ë‚´ì§€ ë§ˆì„¸ìš”."""
        
        # 5. LLM í˜¸ì¶œ
        try:
            answer = await self.llm.acomplete(
                system_prompt=system_prompt,
                user_prompt=user_prompt,
                temperature=0.7
            )
        except Exception as e:
            print(f"[ERROR] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "sources": [],
                "has_results": False
            }
        
        # 6. ê·¼ê±° ë¬¸ì„œ ì •ë³´ êµ¬ì„±
        sources = []
        for result in results:
            metadata = result.metadata
            sources.append({
                "date": metadata.get("date", ""),
                "time_slot": metadata.get("time_slot", ""),
                "chunk_type": result.chunk_type,
                "category": metadata.get("category", ""),
                "text_preview": result.text[:100] + "..." if len(result.text) > 100 else result.text,
                "score": round(result.score, 3)
            })
        
        return {
            "answer": answer,
            "sources": sources,
            "has_results": True
        }

