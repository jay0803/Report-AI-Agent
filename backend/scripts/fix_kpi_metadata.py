"""
KPI ì²­í¬ì˜ keywordsë¥¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë¬¸ìì—´ë¡œ ë³€í™˜
"""
import sys
import codecs
import json
from pathlib import Path

# Windows CMDì—ì„œ UTF-8 ì¶œë ¥ ì„¤ì •
if sys.platform == "win32":
    sys.stdout = codecs.getwriter("utf-8")(sys.stdout.buffer, "strict")
    sys.stderr = codecs.getwriter("utf-8")(sys.stderr.buffer, "strict")

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •
backend_dir = Path(__file__).resolve().parent.parent
kpi_chunks_path = backend_dir / "output" / "KPI ìë£Œ_kpi_chunks.json"

print(f"ğŸ“‚ íŒŒì¼ ë¡œë“œ ì¤‘: {kpi_chunks_path}")

# ì²­í¬ ë¡œë“œ
with open(kpi_chunks_path, "r", encoding="utf-8") as f:
    chunks = json.load(f)

print(f"âœ… {len(chunks)}ê°œ ì²­í¬ ë¡œë“œ ì™„ë£Œ")

# keywordsë¥¼ ë¦¬ìŠ¤íŠ¸ì—ì„œ ë¬¸ìì—´ë¡œ ë³€í™˜
fixed_count = 0
for chunk in chunks:
    metadata = chunk.get("metadata", {})
    keywords = metadata.get("keywords", "")
    
    if isinstance(keywords, list):
        # ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
        metadata["keywords"] = ", ".join(keywords)
        fixed_count += 1

print(f"ğŸ”§ {fixed_count}ê°œ ì²­í¬ì˜ keywords ìˆ˜ì •ë¨")

# ì €ì¥
with open(kpi_chunks_path, "w", encoding="utf-8") as f:
    json.dump(chunks, f, ensure_ascii=False, indent=2)

print(f"âœ… íŒŒì¼ ì €ì¥ ì™„ë£Œ: {kpi_chunks_path}")
print()
print("ì´ì œ ë‹¤ì‹œ ì—…ë¡œë“œë¥¼ ì‹œë„í•˜ì„¸ìš”:")
print("  python test_ingestion_pipeline.py")

