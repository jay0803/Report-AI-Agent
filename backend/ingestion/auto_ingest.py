"""
ìë™ Ingestion ìœ í‹¸ë¦¬í‹°

ì¼ì¼ë³´ê³ ì„œ ì™„ë£Œ ì‹œ ìë™ìœ¼ë¡œ ë²¡í„°DBì— ì €ì¥í•˜ëŠ” í•¨ìˆ˜ë“¤
"""
import os
from pathlib import Path
from typing import Dict, Any
from datetime import date
from dotenv import load_dotenv

# ë³´ê³ ì„œ ì „ìš© .env íŒŒì¼ ë¡œë“œ
project_root = Path(__file__).resolve().parent.parent
report_env_path = project_root / ".env.report"
if report_env_path.exists():
    load_dotenv(report_env_path, override=False)

from app.domain.report.core.canonical_models import CanonicalReport
from app.domain.report.core.chunker import chunk_canonical_report
from app.domain.report.core.embedding_pipeline import get_embedding_pipeline


BATCH_SIZE = 50


def ingest_single_report(
    report: CanonicalReport,
    api_key: str = None
) -> Dict[str, Any]:
    """
    ë‹¨ì¼ ë³´ê³ ì„œë¥¼ ë²¡í„°DBì— ìë™ ì €ì¥
    
    Args:
        report: CanonicalReport ê°ì²´
        api_key: OpenAI API í‚¤ (Noneì´ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ìŒ)
        
    Returns:
        ì—…ë¡œë“œ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    try:
        print(f"\nğŸ“¤ [ìë™ Ingestion] ì‹œì‘: {report.owner} - {report.period_start}")
        
        # 1. ì²­í‚¹ (ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹)
        print("  â³ ì²­í‚¹ ì¤‘...")
        chunks = chunk_canonical_report(report)
        
        if not chunks:
            print("  âš ï¸  ìƒì„±ëœ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return {"success": False, "message": "No chunks generated"}
        
        # ë©”íƒ€ë°ì´í„° ì •ë¦¬ (None ê°’ ì œê±°)
        for chunk in chunks:
            metadata = chunk["metadata"]
            metadata_cleaned = {k: v for k, v in metadata.items() if v is not None}
            chunk["metadata"] = metadata_cleaned
        
        print(f"  âœ… {len(chunks)}ê°œ ì²­í¬ ìƒì„± ì™„ë£Œ")
        
        # 2. ì„ë² ë”© ë° ì €ì¥
        print("  â³ ì„ë² ë”© ìƒì„± ë° ì €ì¥ ì¤‘...")
        embedding_pipeline = get_embedding_pipeline()
        result = embedding_pipeline.process_and_store(chunks)
        
        print(f"  âœ… {result['embeddings_created']}ê°œ ì„ë² ë”© ìƒì„± ì™„ë£Œ")
        print(f"  âœ… ë²¡í„°DB ì—…ë¡œë“œ ì™„ë£Œ: {result['chunks_processed']}ê°œ ì²­í¬")
        print(f"  ğŸ“¦ ì»¬ë ‰ì…˜ ì´ ë¬¸ì„œ ìˆ˜: {result['total_documents']}ê°œ\n")
        
        return {
            "success": True,
            "collection": "reports",
            "uploaded_chunks": result['chunks_processed'],
            "total_documents": result['total_documents']
        }
        
    except Exception as e:
        print(f"  âŒ ìë™ Ingestion ì‹¤íŒ¨: {e}\n")
        return {
            "success": False,
            "message": f"Ingestion failed: {str(e)}",
            "error": str(e)
        }


def ingest_single_report_silent(
    report: CanonicalReport,
    api_key: str = None
) -> bool:
    """
    ë‹¨ì¼ ë³´ê³ ì„œë¥¼ ë²¡í„°DBì— ì €ì¥ (ë¡œê·¸ ìµœì†Œí™” ë²„ì „)
    
    Args:
        report: CanonicalReport ê°ì²´
        api_key: OpenAI API í‚¤
        
    Returns:
        ì„±ê³µ ì—¬ë¶€ (True/False)
    """
    try:
        # ì²­í‚¹ (ì˜ë¯¸ ë‹¨ìœ„ ì²­í‚¹)
        chunks = chunk_canonical_report(report)
        
        if not chunks:
            return False
        
        # ë©”íƒ€ë°ì´í„° ì •ë¦¬ (None ê°’ ì œê±°)
        for chunk in chunks:
            metadata = chunk["metadata"]
            metadata_cleaned = {k: v for k, v in metadata.items() if v is not None}
            chunk["metadata"] = metadata_cleaned
        
        # ì„ë² ë”© ë° ì €ì¥
        embedding_pipeline = get_embedding_pipeline()
        result = embedding_pipeline.process_and_store(chunks)
        
        return result["success"]
        
    except Exception as e:
        print(f"âŒ ë²¡í„°DB ìë™ ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

